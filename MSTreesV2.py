# POC 
# Don't use in production

from __future__ import print_function
import numpy as np, networkx as nx, argparse
from numba import jit
from ete3 import Tree
from subprocess import Popen, PIPE
import sys, os, tempfile, platform, re, tempfile
import time
from datetime import datetime
import multiprocessing

base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

params = dict(
    edmonds_Linux = os.path.join(base_dir, 'binaries', 'edmonds-linux'),
)

start_time = time.time()

@jit(nopython=True)
def contemporary(a,b,c, n_loci) :
    a[0], a[1] = max(min(a[0], n_loci-0.5), 0.5), max(min(a[1], n_loci-0.5), 0.5);
    b, c = max(min(b, n_loci-0.5), 0.5), max(min(c, n_loci-0.5), 0.5)
    if b >= a[0] + c and b >= a[1] + c :
        return False
    elif b == c :
        return True
    s11, s12 = np.sqrt(1-a[0]/n_loci), (2*n_loci - b - c)/2/np.sqrt(n_loci*(n_loci-a[0]))
    v = 1-((n_loci-a[1])*(n_loci-c)/n_loci+(n_loci-b))/2/n_loci
    s21, s22 = 1+a[1]*v/(b-2*n_loci*v), 1+c*v/(b-2*n_loci*v)

    p1 = a[0]*np.log(1-s11*s11) + (n_loci-a[0])*np.log(s11*s11) + (b+c)*np.log(1-s11*s12) + (2*n_loci-b-c)*np.log(s11*s12)
    p2 = a[1]*np.log(1-s21) + (n_loci-a[1])*np.log(s21) + b*np.log(1-s21*s22) + (n_loci-b)*np.log(s21*s22) + c*np.log(1-s22) + (n_loci-c)*np.log(s22)
    return p1 >= p2

def contemporary_16(a,b,c, n_loci) :
    a[0], a[1] = max(min(a[0], n_loci-0.5), 0.5), max(min(a[1], n_loci-0.5), 0.5);
    b, c = max(min(b, n_loci-0.5), 0.5), max(min(c, n_loci-0.5), 0.5)
    if b >= a[0] + c and b >= a[1] + c :
        return False
    elif b == c :
        return True
    s11, s12 = np.sqrt(1-a[0]/n_loci), (2*n_loci - b - c)/2/np.sqrt(n_loci*(n_loci-a[0]))
    v = 1-((n_loci-a[1])*(n_loci-c)/n_loci+(n_loci-b))/2/n_loci
    s21, s22 = 1+a[1]*v/(b-2*n_loci*v), 1+c*v/(b-2*n_loci*v)

    p1 = a[0]*np.log(1-s11*s11) + (n_loci-a[0])*np.log(s11*s11) + (b+c)*np.log(1-s11*s12) + (2*n_loci-b-c)*np.log(s11*s12)
    p2 = a[1]*np.log(1-s21) + (n_loci-a[1])*np.log(s21) + b*np.log(1-s21*s22) + (n_loci-b)*np.log(s21*s22) + c*np.log(1-s22) + (n_loci-c)*np.log(s22)
    return p1 >= p2

def add_args() :
    n_cores = multiprocessing.cpu_count()

    parser = argparse.ArgumentParser(description='For details, see "https://github.com/achtman-lab/GrapeTree/blob/master/README.md".\nIn brief, GrapeTree generates a NEWICK tree to the default output (screen) \nor a redirect output, e.g., a file. ', formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument('--profile', '-p', dest='fname', help='An input filename of a file containing MLST', required=True)
    parser.add_argument('--chunk_size', '-c', dest='chunk_size', help='Chunk size', required=True)
    parser.add_argument('--n_proc', '-n', dest='number_of_processes', help='Number of CPU processes in parallel use. Default is half of available cores.', type=int, default=n_cores // 2)
    parser.add_argument('--dtype', '-d', dest='dtype', help='Data type for numpy arrays in the distance matrix. Provide 16 for np.float16. Default is np.float32.', type=int, default=32)
    parser.add_argument('--sep', '-s', dest='sep', help='Separator for the input file. Default is tab.', default='\t')
    parser.add_argument('--keep_files', '-k', dest='keep_files', help='Keep the files generated by the script. Default is True.', action='store_true')

    
    args = parser.parse_args()
    if args.number_of_processes > n_cores - 1:
        print("Error: n_proc cannot be greater than the total number of cores - 1.")
        sys.exit(1)
    args.profile = args.fname
    args.n_proc = args.number_of_processes
    args.handle_missing = 'pair_delete'
    args.method = 'MSTree'
    args.matrix_type = 'asymmetric'
    args.heuristic = 'harmonic'
    args.branch_recraft = True
    
    args.rows, args.columns = count_lines_and_columns(args.profile)
    print(f"[info] {args.profile} has {args.rows} rows and {args.columns} columns.")

    if args.dtype == 16:
        args.dtype = np.float16
    else:
        args.dtype = np.float32
    
    if args.chunk_size is None:
        if args.rows <= 1000:
            args.chunk_size = 500
        elif args.rows <= 20000:
            args.chunk_size = 5000
        else:
            args.chunk_size = 10000
    else:
        args.chunk_size = int(args.chunk_size)
    
    print(f"[info] The chunk size is set to {args.chunk_size}.")

    return args.__dict__

def count_lines_and_columns(filename, sep='\t'):
        with open(filename, 'r') as f:
            line_count = sum(1 for _ in f) - 1
            f.seek(0)
            column_count = len(next(f).split(sep)) - 1
        return line_count, column_count
    
def parallel_distance(callup) :
    func, index_range = callup
    res = np.memmap(params['dist_file'], dtype=params['dtype'], mode='r+', shape=(params['rows'], params['rows']))
    eval('distance_matrix.'+func)(res[:, index_range[0]:index_range[1]], index_range)
    res.flush()

class distance_matrix(object) :
    @staticmethod
    def get_distance(func):
        int_time = time.time()
        print(f"[info] get_distance method started...")
        from multiprocessing import Pool
        n_profile = params['rows']
        n_proc = min(int(params['n_proc']), n_profile)
        res = np.memmap(params['dist_file'], dtype=params['dtype'], mode='w+', shape=(params['rows'], params['rows']))
        if n_proc > 1 :
            pool = Pool(n_proc)
            indices = np.array([[n_profile*v/n_proc+0.5, n_profile*(v+1)/n_proc+0.5] for v in np.arange(n_proc, dtype=float)], dtype=int)
            pool.map(parallel_distance, [[func, idx] for idx in indices])
            pool.close()
            del pool
        else:
            [parallel_distance([func, [0, n_profile]])]
        res.flush()
        print(f"[info] get_distance method finished in {time.time() - int_time} seconds.")
        return res

    @staticmethod
    def asymmetric(distances, index_range=None) :
        profiles = np.memmap(params['prof_file'], dtype=params['dtype'], mode='r', shape=(params['rows'], params['columns']))
        if index_range is None :
            index_range = [0, profiles.shape[0]]
        presences = (profiles > 0)
        for i2, id in enumerate(np.arange(*index_range)) :
            profile, presence = profiles[id], presences[id]
            diffs = np.sum(((profiles != profile) & presence), axis=1) * float(presence.size)/np.sum(presence)
            distances[:, i2] = diffs
        return distances

    @staticmethod
    def symmetric_link(links) :
        int_time = time.time()
        print(f"[info] symmetric_link method started...")
        profiles = np.memmap(params['prof_file'], dtype=params['dtype'], mode='r', shape=(params['rows'],params['columns']))
        presences = (profiles > 0)
        sl = [ [ s, t, np.sum((profiles[s] != profiles[t]) & presences[s] & presences[t]) ] \
                 for s, t, d in links ]
        print(f"[info] symmetric_link method finished in {time.time() - int_time} seconds.")
        return sl
        
    @staticmethod
    def harmonic(n_str):
        int_time = time.time()
        print(f"[info] harmonic method started...")
        dist = np.memmap(params['dist_file'], dtype=params['dtype'], mode='r', shape=(params['rows'], params['rows']))
        chunk_size = params['chunk_size']
        n_rows, _ = dist.shape
        weights = np.zeros(n_rows, dtype=params['dtype'])
        for start_row in range(0, n_rows, chunk_size):
            end_row = min(start_row + chunk_size, n_rows)
            dist_chunk = dist[start_row:end_row, :]
            harmonic_sums = np.sum(1.0 / (dist_chunk + 0.1), axis=1)
            weights[start_row:end_row] = n_rows / harmonic_sums
        cw = np.vstack([-np.array(n_str, dtype=params['dtype']), weights])
        weights[np.lexsort(cw)] = np.arange(n_rows, dtype=params['dtype']) / n_rows
        print(f"[info] harmonic method finished in {time.time() - int_time} seconds.")
        return weights

class methods(object):
    @staticmethod
    def _asymmetric(weight, **params) :
        int_time = time.time()
        print(f"[info] _asymmetric method started...")
        dist = np.memmap(params['dist_file'], dtype=params['dtype'], mode='r', shape=(params['rows'], params['rows']))
        if params['dtype'] == np.float16:
            int_dtype = np.int16
        else:
            int_dtype = np.int32
        def get_shortcut(dist, weight, cutoff=20) :
            if dist.shape[0] < 3000 :
                cutoff = 2
            elif dist.shape[0] < 10000 :
                cutoff = 5
            elif dist.shape[0] < 30000 :
                cutoff = 10
            link = np.array(np.where(dist < (cutoff+1) ), dtype=int_dtype)
            link = link.T[weight[link[0]] < weight[link[1]]].T
            link = np.vstack([link, dist[tuple(link.tolist())] + weight[link[0]]], dtype=params['dtype'])
            link = link.T[np.lexsort(link)]
            return link[np.unique(link.T[1], return_index=True)[1]].astype(int_dtype)
        try:
            presence = np.arange(weight.shape[0], dtype=int_dtype)
            shortcuts = get_shortcut(dist, weight)
            for (s, t, d) in shortcuts :
                dist[s, dist[s] > dist[t]] = dist[t, dist[s] > dist[t]]
            presence[shortcuts.T[1]] = -1
            dist = dist.T[presence >= 0].T[presence >= 0]
            presence = presence[presence >=0]
            weight2 = weight[presence]
            dist = np.round(dist, 0) + weight2.reshape([weight2.size, -1])
            np.fill_diagonal(dist, 0.0)
            dist_file = params['tempfix'] + '.dist.list'
            with open(dist_file, 'w') as fout :
                for d in dist :
                    fout.write('{0}\n'.format('\t'.join(['{0:.5f}'.format(dd) for dd in (d+(1.-0.000005)) ])))
            del d
            mstree = Popen([params['edmonds_' + platform.system()], dist_file], stdout=PIPE).communicate()[0]
            if isinstance(mstree, bytes) :
                mstree = mstree.decode('utf8')
            mstree = np.array([ br.strip().split() for br in mstree.strip().split('\n')], dtype=float).astype(int)
            assert mstree.size > 0
            mstree.T[2] -= 1
            mstree.T[:2] = presence[mstree.T[:2]]
            m = mstree.tolist() + shortcuts.tolist()
            print(f"[info] _asymmetric method finished in {time.time() - int_time} seconds.")
            return m
        except Exception as e:
            print(e)
            print("[error] Edmonds' algorithm crashed :( .")
            sys.exit(1)

    @staticmethod
    def _branch_recraft(branches, weights) :
        int_time = time.time()
        print(f"[info] _branch_recraft method started...")
        
        contemporary_func = contemporary_16 if params['dtype'] == np.float16 else contemporary        
        
        dist = np.memmap(params['dist_file'], dtype=params['dtype'], mode='r+', shape=(params['rows'], params['rows']))
        n_loci = params['columns']
        group_id, groups, childrens = {b:b for br in branches for b in br[:2]}, \
            {b:[b] for br in branches for b in br[:2]}, \
            {b:[] for br in branches for b in br[:2]}
        branches = sorted(branches, key=lambda br:[dist[br[0], br[1]]] + sorted([weights[br[0]], weights[br[1]]]))
        i = 0
        while i < len(branches) :
            src, tgt, brlen = branches[i]
            sources, targets = groups[group_id[src]], groups[group_id[tgt]]
            tried = {}
            if len(sources) > 1 :
                for w, d, s in sorted(zip(weights[sources], dist[sources, tgt], sources))[:3] :
                    if s == src : break
                    if d < 1.5*dist[src, tgt] :
                        if contemporary_func([dist[s, src], dist[src, s]], d, dist[src, tgt], n_loci) :
                            tried[src], src = s, s
                            break
                while src not in tried :
                    tried[src] = src
                    mid_nodes = sorted([[weights[s], dist[s,tgt], s] for s in childrens[src] if s not in tried and dist[s,tgt] < 2*dist[src, tgt]])
                    for w, d, s in mid_nodes :
                        if d < dist[src, tgt] :
                            if not contemporary_func([dist[src, s], dist[s, src]], dist[src, tgt], d, n_loci) :
                                tried[src], src = s, s
                                break
                        elif w < weights[src] :
                            if contemporary_func([dist[s, src], dist[src, s]], d, dist[src, tgt], n_loci) :
                                tried[src], src = s, s
                                break
                        tried[s] = src
            if len(targets) > 1 :
                for w, d, t in sorted(zip(weights[targets], dist[src, targets], targets))[:3] :
                    if t == tgt : break
                    if d < 1.5*dist[src, tgt] :
                        if contemporary_func([dist[t, tgt], dist[tgt, t]], d, dist[src, tgt], n_loci) :
                            tried[tgt], tgt = t, t
                            break
                while tgt not in tried :
                    tried[tgt] = tgt
                    mid_nodes = sorted([[weights[t], dist[src,t], t] for t in childrens[tgt] if t not in tried and dist[src, t] < 2*dist[src, tgt]])
                    for w, d, s in mid_nodes :
                        if d < dist[src, tgt] :
                            if not contemporary_func([dist[tgt, t], dist[t, tgt]], dist[src, tgt], d, n_loci) :
                                tried[tgt], tgt = t, t
                                break
                        elif w < weights[tgt] :
                            if contemporary_func([dist[t, tgt], dist[tgt, t]], d, dist[src, tgt], n_loci) :
                                tried[tgt], tgt = t, t
                                break
                        tried[t] = tgt
            brlen = dist[src, tgt]
            branches[i] = [src, tgt, brlen]
            if i >= len(branches) - 1 or branches[i+1][2] >= brlen:
                tid = group_id[tgt]
                for t in targets :
                    group_id[t] = group_id[src]
                groups[group_id[src]].extend(groups.pop(tid, []))
                childrens[src].append(tgt)
                childrens[tgt].append(src)
                i += 1
            else :
                branches[i:] = sorted(branches[i:], key=lambda br:br[2])
                
        print(f"[info] _branch_recraft method finished in {time.time() - int_time} seconds.")
        return branches

    @staticmethod
    def _network2tree(branches):
        int_time = time.time()
        print(f"[info] _network2tree method started...")
        names = np.memmap(params['names_file'], dtype='<U100', mode='r', shape=(params['rows'],))
        branches.sort(key=lambda x:x[2], reverse=True)
        branch = []
        in_use = {branches[0][0]:1}
        while len(branches) :
            remain = []
            for br in branches :
                if br[0] in in_use :
                    branch.append(br)
                    in_use[br[1]] = 1
                elif br[1] in in_use :
                    branch.append([br[1], br[0], br[2]])
                    in_use[br[0]] = 1
                else :
                    remain.append(br)
            branches = remain

        tre = Tree()
        nodeFinder = {}

        tre.name = branch[0][0]
        nodeFinder[tre.name] = tre
        for src, tgt, dif in branch :
            node = nodeFinder[src]
            child = node.add_child(name=tgt, dist=dif)
            nodeFinder[child.name] = child
        for node in tre.traverse('postorder') :
            if not node.is_leaf() :
                name = node.name
                node.name = ''
                node.add_child(name=names[name], dist=0.)
            else :
                node.name = names[node.name]
        print(f"[info] _network2tree method finished in {time.time() - int_time} seconds.")
        return tre

    @staticmethod
    def MSTree(embeded, matrix_type='asymmetric', heuristic='harmonic', branch_recraft=True, handle_missing='pair_delete', **params) :
        int_time = time.time()
        print(f"[info] MSTree method started...")
        names = np.memmap(params['names_file'], dtype='<U100', mode='r', shape=(params['rows'],))
        distance_matrix.get_distance(matrix_type)
        weight = eval('distance_matrix.'+heuristic)([len(embeded[n]) for n in names])
        tree = eval('methods._'+matrix_type)(weight, **params)
        if branch_recraft :
            tree = methods._branch_recraft(tree, weight)
        if matrix_type != 'blockwise' :
            tree = distance_matrix.symmetric_link(tree)
        tree = methods._network2tree(tree)
        print(f"[info] MSTree method finished in {time.time() - int_time} seconds.")
        return tree

def nonredundant(names, profiles) :
    int_time = time.time()
    print(f"[info] nonredundant method started...")
    names = np.memmap(params['names_file'], dtype='<U100', mode='r', shape=(params['rows'],))
    profiles = np.memmap(params['prof_file'], dtype='<U10', mode='r', shape=(params['rows'], params['columns']))
    #encoded_profile = np.array([np.unique(p, return_inverse=True)[1]+1 for p in profiles.T]).T
    encoded_profile = np.array([np.unique(p, return_inverse=True)[1] + 1 for p in profiles.T], dtype=np.int32).T
    encoded_profile[ (profiles == '0') | (profiles == 'N') | (profiles == '-')] = 0
    sorted_profiles = np.lexsort(encoded_profile.T)
    names = names[sorted_profiles]
    profiles = encoded_profile[sorted_profiles]
    presence = (np.sum(profiles > 0, 1) > 0)
    names, profiles = names[presence], profiles[presence]
    uniqueness = np.concatenate([[1], np.sum(np.diff(profiles, axis=0) != 0, 1) > 0])
    embeded = {names[0]:[]}
    embeded_group = embeded[names[0]]
    for n, u in zip(names, uniqueness) :
        if u == 0 :
            embeded_group.append(n)
        else :
            embeded[n] = [n]
            embeded_group = embeded[n]
    uniqueness_indexes = uniqueness > 0
    names = names[uniqueness_indexes]
    profiles = profiles[uniqueness_indexes]
    chunk_size = params['chunk_size']
    new_names = np.memmap(params['names_file'], dtype=names.dtype, mode='w+', shape=(len(names),))
    for start in range(0, len(names), chunk_size):
        end = min(start + chunk_size, len(names))
        new_names[start:end] = names[start:end]
    new_names.flush()
    new_profiles = np.memmap(params['prof_file'], dtype=profiles.dtype, mode='w+', shape=profiles.shape)
    for start in range(0, len(profiles), chunk_size):
        end = min(start + chunk_size, len(profiles))
        new_profiles[start:end, :] = profiles[start:end, :]
    new_profiles.flush()
    print(f"[info] nonredundant method finished in {time.time() - int_time} seconds.")
    return new_names, new_profiles, embeded

def profiles_generator(file_path, chunk_size, sep):
    with open(file_path, 'r') as fin:
        header = fin.readline().strip().split(sep)
        allele_cols = [id for id, col in enumerate(header) if id > 0 and not col.startswith('#') and not col.lower() in {'st_id', 'st'}]
        while True:
            names_chunk = []
            profiles_chunk = []
            for _ in range(chunk_size):
                line = fin.readline().strip()
                if not line:
                    break
                part = line.split('\t')
                name = re.sub(r'[\(\)\ \,\"\';]', '_', part[0])
                names_chunk.append(name)
                profile = [part[i].upper() for i in allele_cols]
                profiles_chunk.append(profile)
            if not profiles_chunk:
                break
            yield names_chunk, profiles_chunk
            
def backend(**args) :
    global params
    params.update(args)
    
    temp_file = tempfile.NamedTemporaryFile(delete=True, dir='.')
    params['tempfix'] = temp_file.name
    params['prof_file'] = params['tempfix'] + '.prof.npy'
    params['names_file'] = params['tempfix'] + '.names.npy'
    params['dist_file'] = params['tempfix'] + '.dist.npy'
    params['nwk_file'] = params['tempfix'] + '.nwk'
    
    print(f"[info] The profile file will be saved in {params['prof_file']}.")
    print(f"[info] The names file will be saved in {params['names_file']}.")
    print(f"[info] The distance file will be saved in {params['dist_file']}.")
    print(f"[info] The distance file for edmonds will be saved in {params['tempfix']}.dist.list")
    print(f"[info] The nwk file be saved in {params['nwk_file']}")
        
    int_time = time.time()
    print(f"[info] Processing {params['profile']} in chunks...")
    
    profiles = np.memmap(params['prof_file'], dtype='<U10', mode='w+', shape=(params['rows'], params['columns']))
    names = np.memmap(params['names_file'], dtype='<U100', mode='w+', shape=(params['rows'],))
    chunk_count = 0
    
    for names_chunk, profiles_chunk in profiles_generator(params['fname'], params['chunk_size'], params['sep']):
        profiles_chunk = np.array(profiles_chunk)
        names_chunk = np.array(names_chunk)
        start = chunk_count * params['chunk_size']
        end = start + len(profiles_chunk)
        profiles[start:end] = profiles_chunk
        names[start:end] = names_chunk
        print(f"[info] Chunk {chunk_count} processed with shape {profiles_chunk.shape}")
        chunk_count += 1

    profiles.flush()
    names.flush()
    print(f"[info] Processing finished in {time.time() - int_time} seconds.")
    
    names, profiles, embeded = nonredundant(names, profiles)
    print(f"[info] New shape of profiles: {profiles.shape}")
    print(f"[info] New shape of names: {names.shape}")
    params['rows'] = profiles.shape[0]
    params['columns'] = profiles.shape[1]
    
    with temp_file as f :
        tre = eval('methods.' + params['method'])(embeded, **params)
        maxDist = 0.
        for node in tre.iter_descendants() :
            if node.dist > maxDist: maxDist = node.dist
        if maxDist > 3 :
            for node in tre.iter_descendants('postorder') :
                if node.dist < 0.1 and node.dist > 0 :
                    for s in node.get_sisters() :
                        s.dist += node.dist
                    node.dist = 0
        for leaf in tre.get_leaves() :
            embeded_group = embeded[leaf.name]
            if len(embeded_group) > 1 :
                leaf.name = ''
                for n in embeded_group :
                    leaf.add_child(name=n, dist=0.)

        if not params['keep_files']:
            print(f"[info] Removing temporary files...")
            try:
                os.unlink(params['prof_file'])
                os.unlink(params['names_file'])
                os.unlink(params['dist_file'])
                os.unlink(f"{params['tempfix']}.dist.list")
            except :
                print(f"[error] Error in removing temporary files...")
                pass
            
        with open(params['nwk_file'], 'w') as f:
            f.write(tre.write(format=1).replace("'", ""))
    
        return

if __name__ == '__main__' :
    print("#########################################################")
    print("####       !!! DON'T USE IN PRODUCTION !!!       ########")
    print("#########################################################")
    print(f"[info] MSTreesV2 started at {datetime.now()}...")
    print("#########################################################")
    backend(**add_args())
    print(f"[info] Process completed in {time.time() - start_time} seconds.")
    print("#########################################################")
    print(f"[info] MSTreesV2 finished at {datetime.now()}...")
    print("#########################################################")