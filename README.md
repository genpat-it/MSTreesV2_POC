# MSTreesV2.py

This script extracts only the methods used for the MSTreesV2 pipeline, which were originally implemented in the [MSTree.py](https://github.com/achtman-lab/GrapeTree/blob/master/module/MSTrees.py) script.

The enhanced script introduces two key concepts: chunks and memory-mapped files (memmap).

* Chunks: The script now processes data in chunks, which can significantly improve performance when dealing with large datasets. Instead of loading the entire dataset into memory at once, the script loads and processes smaller subsets of the data (chunks), one at a time.

* Memory-mapped files (memmap): The script uses memory-mapped files, a method that allows a file or a device to be read from and written to as if it were an array in memory. This is achieved by mapping a disk file to a segment of memory. Memory-mapped files can be used for accessing small segments of large files without reading the entire file into memory.

## Disclaimer
This script is a proof of concept (POC) and is not intended for production use. It is a modified version of the original script, tailored by the GENPAT team and is currently in an unstable state as it is under active development.

## Key Features
- **Optimized TSV Matrix Handling**: The key upgrade in this version is the optimized handling of large TSV matrix profiles, achieved through the '-p' option.

## Development Todos
1. **Skip Phases**: Allow the script to skip phases when precomputed `.npy` files (e.g., profiles, names, or distance matrix) are passed.
2. **Implement Remaining Functions**: Test and update the remaining functions from the original script.
3. **Validate results**: Especially when float16 dtype is used.


## Usage of float16 dtype
* Utilizing float16 as the data type inhibits the just-in-time (JIT) compilation of the contemporary method.
* The Newick tree (nwk) resulting from the use of float16 cannot be directly compared with the Newick tree obtained from the original script.
* float16 reduces precision, especially in divisions and sorting operations, which may not be as precise.
  
## Original Script
The original script can be found at:
- [MSTrees.py](https://github.com/achtman-lab/GrapeTree/blob/master/module/MSTrees.py)

To use this script:
```bash
git clone https://github.com/achtman-lab/GrapeTree/
cd GrapeTree/module
git clone https://github.com/genpat-it/MSTreesV2_POC
```

### Testing Environment
- **Dataset**: 80000 samples, 4000 loci
- **System Specs**: 32GB of memory

## Usage

```bash
$ python MSTreesV2.py -h
#########################################################
####       !!! DON'T USE IN PRODUCTION !!!       ########
#########################################################
[info] MSTreesV2 started at 2024-05-16 17:28:27.278087...
#########################################################
usage: MSTreesV2.py [-h] --profile FNAME --chunk_size CHUNK_SIZE [--n_proc NUMBER_OF_PROCESSES] [--dtype DTYPE] [--sep SEP] [--keep_files]

For details, see "https://github.com/achtman-lab/GrapeTree/blob/master/README.md".
In brief, GrapeTree generates a NEWICK tree to the default output (screen) 
or a redirect output, e.g., a file. 

options:
  -h, --help            show this help message and exit
  --profile FNAME, -p FNAME
                        An input filename of a file containing MLST
  --chunk_size CHUNK_SIZE, -c CHUNK_SIZE
                        Chunk size
  --n_proc NUMBER_OF_PROCESSES, -n NUMBER_OF_PROCESSES
                        Number of CPU processes in parallel use. Default is half of available cores.
  --dtype DTYPE, -d DTYPE
                        Data type for numpy arrays in the distance matrix. Provide 16 for np.float16. Default is np.float32.
  --sep SEP, -s SEP     Separator for the input file. Default is tab.
  --keep_files, -k      Keep the files generated by the script. Default is True.
```

## Test
This script generates a dummy matrix of size 80000x4000, with a similarity percentage of 5%. Each allele call is extracted from the same bin that belongs to the locus. Each locus can have up to 10 unique crc32 values.

```bash
$ python dummy_generator.py 80000 4000 5 80000x4000_5.tsv
Dummy dataset with 80000 samples, 4000 columns, and 5% similarity saved to 80000x4000_5.tsv
```

Execute the script with the default `-p` pipeline option, processing in chunks of 10000 rows at a time (`-c`), utilizing 120 cores (`-n`), with data type set to float16 (`-d`), and retaining the temporary files generated during the process (`-k`).

```bash
$ /usr/bin/time -v python MSTreesV2.py -p 80000x4000_5.tsv -c 10000 -n 120 -d 16 -k

#########################################################
####       !!! DON'T USE IN PRODUCTION !!!       ########
#########################################################
[info] MSTreesV2 started at 2024-05-16 17:24:18.926149...
#########################################################
[info] 80000x4000_5.tsv has 80000 rows and 4000 columns.
[info] The chunk size is set to 10000.
[info] The profile file will be saved in /MSTrees_fork/github/tmp6zevps6_.prof.npy.
[info] The names file will be saved in /MSTrees_fork/github/tmp6zevps6_.names.npy.
[info] The distance file will be saved in /MSTrees_fork/github/tmp6zevps6_.dist.npy.
[info] The distance file for edmonds will be saved in /MSTrees_fork/github/tmp6zevps6_.dist.list
[info] The nwk file be saved in /MSTrees_fork/github/tmp6zevps6_.nwk
[info] Processing 80000x4000_5.tsv in chunks...
[info] Chunk 0 processed with shape (10000, 4000)
[info] Chunk 1 processed with shape (10000, 4000)
[info] Chunk 2 processed with shape (10000, 4000)
[info] Chunk 3 processed with shape (10000, 4000)
[info] Chunk 4 processed with shape (10000, 4000)
[info] Chunk 5 processed with shape (10000, 4000)
[info] Chunk 6 processed with shape (10000, 4000)
[info] Chunk 7 processed with shape (10000, 4000)
[info] Processing finished in 186.30022048950195 seconds.
[info] nonredundant method started...
[info] nonredundant method finished in 142.98293256759644 seconds.
[info] New shape of profiles: (76001, 4000)
[info] New shape of names: (76001,)
[info] MSTree method started...
[info] get_distance method started...

(to be continued)
```